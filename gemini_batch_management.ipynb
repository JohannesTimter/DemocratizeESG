{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T12:55:47.608810Z",
     "start_time": "2025-09-18T12:55:46.097182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google import genai\n",
    "import json\n",
    "\n",
    "client = genai.Client()"
   ],
   "id": "e3600adb94ca5bc1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T23:52:43.880634Z",
     "start_time": "2025-09-17T23:52:36.434639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_file_path = 'batchProcessing_file_promptTemplate3.json'\n",
    "\n",
    "print(f\"Uploading JSONL file: {json_file_path}\")\n",
    "batch_input_file = client.files.upload(\n",
    "    file=json_file_path\n",
    "    )\n",
    "print(f\"Uploaded JSONL file: {batch_input_file.name}\")\n",
    "\n",
    "print(\"\\nCreating batch job...\")\n",
    "batch_job_from_file = client.batches.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    src=batch_input_file.name,\n",
    "    config={\n",
    "        'display_name': 'batchProcessing_file_promptTemplate3',\n",
    "    }\n",
    ")\n",
    "print(f\"Created batch job from file: {batch_job_from_file.name}\")\n",
    "print(\"You can now monitor the job status using its name.\")"
   ],
   "id": "945c20d51e86ef24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading JSONL file: batchProcessing_file_promptTemplate3.json\n",
      "Uploaded JSONL file: files/9dolr0uy2hvk\n",
      "\n",
      "Creating batch job...\n",
      "Created batch job from file: batches/i519yu8mjbyuqq8lyhnp13b0fies15v1x4bz\n",
      "You can now monitor the job status using its name.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T12:55:57.108574Z",
     "start_time": "2025-09-18T12:55:56.694323Z"
    }
   },
   "source": [
    "completed_states = set([\n",
    "    'JOB_STATE_SUCCEEDED',\n",
    "    'JOB_STATE_FAILED',\n",
    "    'JOB_STATE_CANCELLED',\n",
    "    'JOB_STATE_EXPIRED',\n",
    "])\n",
    "\n",
    "print(\"Listing recent batch jobs:\\n\")\n",
    "\n",
    "# Note: The list API currently doesn't return inlined_responses.\n",
    "# As a workaround,you can make a `get` call for inline jobs to see their results.\n",
    "batches = client.batches.list(config={'page_size': 10})\n",
    "\n",
    "for b in batches.page:\n",
    "    print(f\"Job Name: {b.name}\")\n",
    "    print(f\"  - Display Name: {b.display_name}\")\n",
    "    print(f\"  - State: {b.state.name}\")\n",
    "    print(f\"  - Create Time: {b.create_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    if b.state.name in completed_states:\n",
    "        print(f\"  - End Time: {b.end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Check if it was an inline job (no destination file)\n",
    "    if b.dest is not None:\n",
    "      if not b.dest.file_name:\n",
    "        full_job = client.batches.get(name=b.name)\n",
    "        if full_job.inlined_responses:\n",
    "            print(\"  - Type: Inline ({} responses)\".format(len(full_job.inlined_responses)))\n",
    "      else:\n",
    "          print(f\"  - Type: File-based (Output: {b.dest.file_name})\")\n",
    "\n",
    "    print(\"-\" * 20)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing recent batch jobs:\n",
      "\n",
      "Job Name: batches/i519yu8mjbyuqq8lyhnp13b0fies15v1x4bz\n",
      "  - Display Name: batchProcessing_file_promptTemplate3\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-17 23:53:22\n",
      "  - End Time: 2025-09-18 06:17:19\n",
      "  - Type: File-based (Output: files/batch-i519yu8mjbyuqq8lyhnp13b0fies15v1x4bz)\n",
      "--------------------\n",
      "Job Name: batches/9f8onr8qkxes8tedtd357x7k6s6ceaajw72p\n",
      "  - Display Name: batchProcessing_file_promptTemplate2\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-14 20:00:36\n",
      "  - End Time: 2025-09-15 04:32:14\n",
      "  - Type: File-based (Output: files/batch-9f8onr8qkxes8tedtd357x7k6s6ceaajw72p)\n",
      "--------------------\n",
      "Job Name: batches/oob9e7t1o0crucxqe7b16aeq3k5k6gb47d5t\n",
      "  - Display Name: batchProcessing_file_promptTemplate1\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-13 00:29:55\n",
      "  - End Time: 2025-09-13 05:49:04\n",
      "  - Type: File-based (Output: files/batch-oob9e7t1o0crucxqe7b16aeq3k5k6gb47d5t)\n",
      "--------------------\n",
      "Job Name: batches/11wqncexbtisoa2rrbvc9tqrtcm4qb1wxv25\n",
      "  - Display Name: quantas_batch_file_with_thinking_corrected_with_json_schema\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-12 18:31:09\n",
      "  - End Time: 2025-09-12 18:39:49\n",
      "  - Type: File-based (Output: files/batch-11wqncexbtisoa2rrbvc9tqrtcm4qb1wxv25)\n",
      "--------------------\n",
      "Job Name: batches/i9m070qk0ebqez5f3my485jreq4r6jrhut3x\n",
      "  - Display Name: quantas_batch_file_with_thinking_corrected\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-12 18:25:13\n",
      "  - End Time: 2025-09-12 18:39:55\n",
      "  - Type: File-based (Output: files/batch-i9m070qk0ebqez5f3my485jreq4r6jrhut3x)\n",
      "--------------------\n",
      "Job Name: batches/5dfzbzpknv9dkwjdy3sx1w9g21u409g92aoj\n",
      "  - Display Name: my-batch-job-with-file-and-thoughts-thinking_config\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-12 16:59:15\n",
      "  - End Time: 2025-09-12 17:00:40\n",
      "  - Type: File-based (Output: files/batch-5dfzbzpknv9dkwjdy3sx1w9g21u409g92aoj)\n",
      "--------------------\n",
      "Job Name: batches/nm1ycsfts46b6vh2090bh4xyo9plyvs0dr06\n",
      "  - Display Name: quantas-airlines-inline-batch-test1\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-12 16:51:34\n",
      "  - End Time: 2025-09-12 17:00:44\n",
      "--------------------\n",
      "Job Name: batches/ff0deax8tnaay5rr0gqkn6g22pl3pd4orcrk\n",
      "  - Display Name: extraction_attempt_3\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-11 22:12:59\n",
      "  - End Time: 2025-09-12 10:09:13\n",
      "  - Type: File-based (Output: files/batch-ff0deax8tnaay5rr0gqkn6g22pl3pd4orcrk)\n",
      "--------------------\n",
      "Job Name: batches/vnb8p71ws0ug2mgdkb6vmo11xlxspy40okyd\n",
      "  - Display Name: my-batch-job-with-file-and-thoughts-thinking_config\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-11 16:44:56\n",
      "  - End Time: 2025-09-11 17:48:30\n",
      "  - Type: File-based (Output: files/batch-vnb8p71ws0ug2mgdkb6vmo11xlxspy40okyd)\n",
      "--------------------\n",
      "Job Name: batches/f9twk9y9jhwrgfyjrpq9h3ucnqr5cypgorio\n",
      "  - Display Name: my-batch-job-with-file-and-thoughts\n",
      "  - State: JOB_STATE_SUCCEEDED\n",
      "  - Create Time: 2025-09-11 00:14:25\n",
      "  - End Time: 2025-09-11 03:29:17\n",
      "  - Type: File-based (Output: files/batch-f9twk9y9jhwrgfyjrpq9h3ucnqr5cypgorio)\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T13:08:26.387476Z",
     "start_time": "2025-09-18T13:08:24.557032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_job = client.batches.get(name=\"batches/i519yu8mjbyuqq8lyhnp13b0fies15v1x4bz\")\n",
    "\n",
    "if batch_job.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "    # The output is in another file.\n",
    "    result_file_name = batch_job.dest.file_name\n",
    "    print(f\"Results are in file: {result_file_name}\")\n",
    "\n",
    "    print(\"\\nDownloading and parsing result file content...\")\n",
    "    file_content_bytes = client.files.download(file=result_file_name)\n",
    "    file_content = file_content_bytes.decode('utf-8')\n",
    "\n",
    "    pretty_file_content = \"\"\n",
    "\n",
    "    #The result file is also a JSONL file. Parse and print each line.\n",
    "    #for line in file_content.splitlines():\n",
    "    #  if line:\n",
    "    #    parsed_response = json.loads(line)\n",
    "    #    response_text = parsed_response['response']['candidates'][0]['content']['parts'][0]['text']\n",
    "    #    print(response_text)\n",
    "    #    print(json.dumps(response_text, indent=4))\n",
    "\n",
    "\n",
    "    #   pretty_file_content = pretty_file_content + json.dumps(parsed_response, indent=2) + \"\\n\"\n",
    "        #Pretty-print the JSON for readability\n",
    "    #    print(json.dumps(parsed_response, indent=2))\n",
    "    #    print(\"-\" * 20)\n",
    "\n",
    "    json_file_path = 'batch_output_promptTemplate2.json'\n",
    "    print(f\"\\nCreating JSONL file: {json_file_path}\")\n",
    "    with open(json_file_path, 'w') as f:\n",
    "      f.write(json.dumps(file_content) + '\\n')\n",
    "\n",
    "else:\n",
    "    print(f\"Job did not succeed. Final state: {batch_job.state.name}\")"
   ],
   "id": "74b3e33d6a42f1f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are in file: files/batch-i519yu8mjbyuqq8lyhnp13b0fies15v1x4bz\n",
      "\n",
      "Downloading and parsing result file content...\n",
      "\n",
      "Creating JSONL file: batch_output_promptTemplate2.json\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
