{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuXYZBmuHYxa"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "Q2fjiWA5HetI",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:26:31.877329Z",
     "start_time": "2025-09-02T21:26:31.869184Z"
    }
   },
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juLxdbNPIiPF"
   },
   "source": [
    "# Gemini API: Asynchronous Python requests\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBfCOtXROsVR"
   },
   "source": [
    "This notebook will show you how to make asynchronous and parallel requests using the Gemini API's Python SDK and Python 3's [`asyncio`](https://docs.python.org/3/library/asyncio.html) standard library.\n",
    "\n",
    "The examples here run in Google Colab and use the implicit event loop supplied in Colab. You can also run these commands interactively using the `asyncio` REPL (invoked with `python -m asyncio`), or you can manage the [event loop](https://docs.python.org/3/library/asyncio-eventloop.html) yourself."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CUCIiuo60vgI",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:46:41.935183Z",
     "start_time": "2025-09-02T21:46:40.929350Z"
    }
   },
   "source": [
    "%pip install -qU 'google-genai>=1.0.0' aiohttp"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: \"'google-genai\": Expected package name at the start of dependency specifier\n",
      "    'google-genai\n",
      "    ^\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1GCRqAyDOpz"
   },
   "source": [
    "## Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](../quickstarts/Authentication.ipynb) quickstart for an example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JiXbEhpl_0ya",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:46:15.817104Z",
     "start_time": "2025-09-02T21:46:14.826553Z"
    }
   },
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzU9xvdMFhNp"
   },
   "source": [
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](./Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PQgPpzjsFzRR",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:46:17.730035Z",
     "start_time": "2025-09-02T21:46:17.724185Z"
    }
   },
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash\",\"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtOfRg-UFSuB"
   },
   "source": [
    "## Using local files\n",
    "\n",
    "This simple example shows how can you use local files (presumed to load quickly) with the SDK's `async` API."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D1Sw3UzEFekL",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:46:19.594866Z",
     "start_time": "2025-09-02T21:46:19.590407Z"
    }
   },
   "source": [
    "prompt = \"Describe this image in just 3 words.\"\n",
    "\n",
    "img_filenames = [\"firefighter.jpg\", \"elephants.jpeg\", \"jetpack.jpg\"]\n",
    "img_dir = \"https://storage.googleapis.com/generativeai-downloads/images/\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0NBs55iFwyR"
   },
   "source": [
    "Start by downloading the files locally."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iRGHeraNFwTL",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:46:58.954468Z",
     "start_time": "2025-09-02T21:46:58.776454Z"
    }
   },
   "source": "!wget -nv {img_dir}{{{','.join(img_filenames)}}}",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "ERROR: cannot verify storage.googleapis.com's certificate, issued by `/C=US/O=Google Trust Services/CN=WR2':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "ERROR: certificate common name `*.storage.googleapis.com' doesn't match requested host name `storage.googleapis.com'.\n",
      "To connect to storage.googleapis.com insecurely, use `--no-check-certificate'.\n",
      "Unable to establish SSL connection.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyUIpSnnJD4W"
   },
   "source": [
    "The async code uses the `aio.models.generate_content` method to invoke the API. Most async API methods can be found in the [`aio`](https://googleapis.github.io/python-genai/genai.html#genai.client.AsyncClient) namespace.\n",
    "\n",
    "Note that this code is not run in parallel. The async call indicates that the event loop *can* yield to other tasks, but there are no other tasks scheduled in this code. This may be sufficient, e.g. if you are running this in a web server request handler as it will allow the handler to yield to other tasks while waiting for the API response."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AXcB_yPGFlZd",
    "ExecuteTime": {
     "end_time": "2025-09-02T21:55:46.207407Z",
     "start_time": "2025-09-02T21:55:45.608729Z"
    }
   },
   "source": [
    "import PIL\n",
    "\n",
    "async def describe_local_images():\n",
    "\n",
    "  for img_filename in img_filenames:\n",
    "\n",
    "    with open(img_filename, 'rb') as f:\n",
    "      image_bytes = f.read()\n",
    "    r = await client.aio.models.generate_content(\n",
    "        model=MODEL_ID,\n",
    "        contents=[prompt, image_bytes]\n",
    "    )\n",
    "    print(r.text)\n",
    "\n",
    "\n",
    "await describe_local_images()"
   ],
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "12 validation errors for _GenerateContentParameters\ncontents.Content\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.str\n  Input should be a valid string [type=string_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\ncontents.File\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.Part\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[str,File,Part]].1.str\n  Input should be a valid string, unable to parse raw data as a unicode string [type=string_unicode, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_unicode\ncontents.list[union[str,File,Part]].1.File\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[str,File,Part]].1.Part\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.Content\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.str\n  Input should be a valid string, unable to parse raw data as a unicode string [type=string_unicode, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_unicode\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.File\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.Part\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.list[union[str,File,Part]]\n  Input should be a valid list [type=list_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValidationError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m      9\u001B[39m     r = \u001B[38;5;28;01mawait\u001B[39;00m client.aio.models.generate_content(\n\u001B[32m     10\u001B[39m         model=MODEL_ID,\n\u001B[32m     11\u001B[39m         contents=[prompt, image_bytes]\n\u001B[32m     12\u001B[39m     )\n\u001B[32m     13\u001B[39m     \u001B[38;5;28mprint\u001B[39m(r.text)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m describe_local_images()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36mdescribe_local_images\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(img_filename, \u001B[33m'\u001B[39m\u001B[33mrb\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m      8\u001B[39m   image_bytes = f.read()\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m r = \u001B[38;5;28;01mawait\u001B[39;00m client.aio.models.generate_content(\n\u001B[32m     10\u001B[39m     model=MODEL_ID,\n\u001B[32m     11\u001B[39m     contents=[prompt, image_bytes]\n\u001B[32m     12\u001B[39m )\n\u001B[32m     13\u001B[39m \u001B[38;5;28mprint\u001B[39m(r.text)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\models.py:8210\u001B[39m, in \u001B[36mAsyncModels.generate_content\u001B[39m\u001B[34m(self, model, contents, config)\u001B[39m\n\u001B[32m   8208\u001B[39m response = types.GenerateContentResponse()\n\u001B[32m   8209\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m remaining_remote_calls_afc > \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m8210\u001B[39m   response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._generate_content(\n\u001B[32m   8211\u001B[39m       model=model, contents=contents, config=parsed_config\n\u001B[32m   8212\u001B[39m   )\n\u001B[32m   8213\u001B[39m   remaining_remote_calls_afc -= \u001B[32m1\u001B[39m\n\u001B[32m   8214\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m remaining_remote_calls_afc == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\models.py:6929\u001B[39m, in \u001B[36mAsyncModels._generate_content\u001B[39m\u001B[34m(self, model, contents, config)\u001B[39m\n\u001B[32m   6922\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate_content\u001B[39m(\n\u001B[32m   6923\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   6924\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m   6927\u001B[39m     config: Optional[types.GenerateContentConfigOrDict] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   6928\u001B[39m ) -> types.GenerateContentResponse:\n\u001B[32m-> \u001B[39m\u001B[32m6929\u001B[39m   parameter_model = \u001B[43mtypes\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_GenerateContentParameters\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   6930\u001B[39m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   6931\u001B[39m \u001B[43m      \u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   6932\u001B[39m \u001B[43m      \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   6933\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6935\u001B[39m   request_url_dict: Optional[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]]\n\u001B[32m   6937\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._api_client.vertexai:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:253\u001B[39m, in \u001B[36mBaseModel.__init__\u001B[39m\u001B[34m(self, **data)\u001B[39m\n\u001B[32m    251\u001B[39m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[32m    252\u001B[39m __tracebackhide__ = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m253\u001B[39m validated_self = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[32m    255\u001B[39m     warnings.warn(\n\u001B[32m    256\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m\n\u001B[32m    257\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    258\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m    259\u001B[39m         stacklevel=\u001B[32m2\u001B[39m,\n\u001B[32m    260\u001B[39m     )\n",
      "\u001B[31mValidationError\u001B[39m: 12 validation errors for _GenerateContentParameters\ncontents.Content\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.str\n  Input should be a valid string [type=string_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\ncontents.File\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.Part\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=['Describe this image in ...0\\xa2\\x8a(\\x03\\xff\\xd9'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[str,File,Part]].1.str\n  Input should be a valid string, unable to parse raw data as a unicode string [type=string_unicode, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_unicode\ncontents.list[union[str,File,Part]].1.File\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[str,File,Part]].1.Part\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.Content\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.str\n  Input should be a valid string, unable to parse raw data as a unicode string [type=string_unicode, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_unicode\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.File\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.Part\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type\ncontents.list[union[Content,str,File,Part,list[union[str,File,Part]]]].1.list[union[str,File,Part]]\n  Input should be a valid list [type=list_type, input_value=b'\\xff\\xd8\\xff\\xe0\\x00\\x1...00\\xa2\\x8a(\\x03\\xff\\xd9', input_type=bytes]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg4Ki_vKRpV1"
   },
   "source": [
    "## Downloading images asynchronously and in parallel\n",
    "\n",
    "This example shows a more real-world case where an image is downloaded from an external source using the async HTTP library [`aiohttp`](https://pypi.org/project/aiohttp), and each image is processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RdykoS-G__Tv"
   },
   "outputs": [],
   "source": [
    "import io, aiohttp, asyncio\n",
    "\n",
    "async def download_image(session: aiohttp.ClientSession, img_url: str) -> PIL.Image:\n",
    "  \"\"\"Returns a PIL.Image object from the provided URL.\"\"\"\n",
    "  async with session.get(img_url) as img_resp:\n",
    "    buffer = io.BytesIO()\n",
    "    buffer.write(await img_resp.read())\n",
    "    return PIL.Image.open(buffer)\n",
    "\n",
    "\n",
    "async def process_image(img_future: asyncio.Future[PIL.Image]) -> str:\n",
    "  \"\"\"Summarise the image using the Gemini API.\"\"\"\n",
    "  # This code uses a future so that it defers work as late as possible. Using a\n",
    "  # concrete Image object would require awaiting the download task before *queueing*\n",
    "  # this content generation task - this approach chains the futures together\n",
    "  # so that the download only starts when the generation is scheduled.\n",
    "  r = await client.aio.models.generate_content(\n",
    "      model=MODEL_ID,\n",
    "      contents=[prompt, await img_future]\n",
    "  )\n",
    "  return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "447qlmtD2kWe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download and content generation queued for 3 images.\n",
      "\n",
      "Wild elephant family.\n",
      "\n",
      "Jetpack backpack concept\n",
      "\n",
      "Cat, person, tree.\n"
     ]
    }
   ],
   "source": [
    "async def download_and_describe():\n",
    "\n",
    "  async with aiohttp.ClientSession() as sesh:\n",
    "    response_futures = []\n",
    "    for img_filename in img_filenames:\n",
    "\n",
    "      # Create the image download tasks (this does not schedule them yet).\n",
    "      img_future = download_image(sesh, img_dir + img_filename)\n",
    "\n",
    "      # Kick off the Gemini API request using the pending image download tasks.\n",
    "      text_future = process_image(img_future)\n",
    "\n",
    "      # Save the reference so they can be processed as they complete.\n",
    "      response_futures.append(text_future)\n",
    "\n",
    "    print(f\"Download and content generation queued for {len(response_futures)} images.\")\n",
    "\n",
    "    # Process responses as they complete (may be a different order). The tasks are started here.\n",
    "    for response in asyncio.as_completed(response_futures):\n",
    "      print()\n",
    "      print(await response)\n",
    "\n",
    "\n",
    "await download_and_describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOU0_lELKKFG"
   },
   "source": [
    "In the above example, a coroutine is created for each image that both downloads and then summarizes the image. The coroutines are executed in the final step, in the `as_completed` loop. To start them as early as possible without blocking the other work, you could wrap `download_image` in [`asyncio.ensure_future`](https://docs.python.org/3/library/asyncio-future.html#asyncio.ensure_future), but for this example the execution has been deferred to keep the creation and execution concerns separate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uAy7qOkOGHi"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "* Check out the [`AsyncClient`](https://googleapis.github.io/python-genai/genai.html#genai.client.AsyncClient) class in the Python SDK reference.\n",
    "* Read more on Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html) library"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T22:09:07.551849Z",
     "start_time": "2025-09-02T22:08:57.880772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.genai import types\n",
    "\n",
    "with open('firefighter.jpg', 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model='gemini-2.5-flash',\n",
    "  contents=[\n",
    "    types.Part.from_bytes(\n",
    "      data=image_bytes,\n",
    "      mime_type='image/jpeg',\n",
    "    ),\n",
    "    'Caption this image.'\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few caption options for the image:\n",
      "\n",
      "**Descriptive:**\n",
      "*   A simple black and white stick figure drawing of a person looking up at a cat perched on a tree branch.\n",
      "*   A stick figure wearing a cap stands on the ground, hands on hips, gazing up at a contented cat in a tree.\n",
      "*   A drawing featuring a large tree with a small, smiling cat on one of its branches, observed by a stick figure person below.\n",
      "\n",
      "**Narrative/Interpretive:**\n",
      "*   The classic dilemma: a cat up a tree, and a human trying to figure out how to get it down.\n",
      "*   \"How did you get up there, Mittens?\"\n",
      "*   A moment of contemplation as the stick figure considers how to retrieve the cat from the tree.\n",
      "*   The cat is enjoying the view, while the person on the ground seems a bit perplexed.\n",
      "\n",
      "**Humorous:**\n",
      "*   \"I'm not stuck, human. This is my new high-rise apartment.\" - The cat, probably.\n",
      "*   Looks like someone forgot their cat-retrieval pole.\n",
      "*   The ultimate game of 'fetch' where only one player is participating.\n",
      "*   \"Just admiring the scenery up here, no big deal.\"\n",
      "\n",
      "**Concise:**\n",
      "*   Cat in a tree.\n",
      "*   Stick figure and cat.\n",
      "*   Up a tree.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T22:14:22.557475Z",
     "start_time": "2025-09-02T22:13:59.634352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.genai import types\n",
    "\n",
    "img_filenames = [\"firefighter.jpg\", \"elephants.jpeg\", \"jetpack.jpg\"]\n",
    "images_bytes = []\n",
    "\n",
    "for img_filename in img_filenames:\n",
    "  with open(img_filename, 'rb') as f:\n",
    "      images_bytes.append(f.read())\n",
    "\n",
    "\n",
    "\n",
    "for image_bytes in images_bytes:\n",
    "  response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[\n",
    "      types.Part.from_bytes(\n",
    "        data=image_bytes,\n",
    "        mime_type='image/jpeg',\n",
    "      ),\n",
    "      'Caption this image.'\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  print(response.text)\n",
    "  print(\"---\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few options for a caption:\n",
      "\n",
      "**Descriptive:**\n",
      "*   A simple, childlike drawing depicts a stick figure person standing below a tall tree, looking up at a cat perched on one of its branches.\n",
      "*   A stick figure person with a hat looks up at a cat sitting on a tree branch.\n",
      "\n",
      "**Humorous/Relatable:**\n",
      "*   The classic cat-in-a-tree scenario, stick-figure style.\n",
      "*   Someone's planning a rescue, or just wondering how the cat got up there.\n",
      "*   Cat: \"I see no problem here.\" Person: \"I beg to differ.\"\n",
      "*   The eternal question: how to get the cat down?\n",
      "*   Looks like a job for the local fire department... or a very patient human.\n",
      "\n",
      "**Concise:**\n",
      "*   Cat in a tree.\n",
      "*   Up a tree.\n",
      "*   Standoff.\n",
      "*   Feline high, human low.\n",
      "---\n",
      "Here are several caption options for the image, ranging from descriptive to more evocative:\n",
      "\n",
      "**Concise & Descriptive:**\n",
      "*   An elephant family, including a young calf, at the edge of a lush green forest.\n",
      "*   A small herd of Asian elephants near a dirt path in the wilderness.\n",
      "*   Four elephants, with a baby calf, surrounded by vibrant greenery.\n",
      "\n",
      "**Evocative & Engaging:**\n",
      "*   Gentle giants: An elephant family and their adorable calf in their natural habitat.\n",
      "*   A tender moment with a wild elephant herd, showcasing the bond between mother and calf.\n",
      "*   Life in the wild: A young elephant calf stays close to its protective family amidst the lush jungle.\n",
      "*   Peaceful coexistence: Elephants graze along a forest trail, with a tiny calf in tow.\n",
      "\n",
      "**More Detailed:**\n",
      "*   A small herd of Asian elephants, featuring a young calf, stands gracefully by a dirt track, framed by tall green grass and dense forest foliage.\n",
      "*   Four elephants, including a charming calf, find respite and food at the border of a dense forest and a gravel path.\n",
      "---\n",
      "A hand-drawn concept sketch outlines a \"Jetpack Backpack\" designed for both utility and personal flight. The innovative backpack features retractable, steam-powered boosters for \"green/clean\" operation, a 15-minute battery life, and USB-C charging. It also prioritizes practicality, appearing as a normal, lightweight backpack with padded strap support and the capacity to fit an 18-inch laptop.\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T22:17:07.175681Z",
     "start_time": "2025-09-02T22:16:45.534421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.genai import types\n",
    "\n",
    "async def describe_local_images(images_bytes):\n",
    "  for image_bytes in images_bytes:\n",
    "    response = await client.aio.models.generate_content(\n",
    "      model='gemini-2.5-flash',\n",
    "      contents=[\n",
    "        types.Part.from_bytes(\n",
    "          data=image_bytes,\n",
    "          mime_type='image/jpeg',\n",
    "        ),\n",
    "        'Caption this image.'\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    print(response.text)\n",
    "    print(\"---\")\n",
    "\n",
    "img_filenames = [\"firefighter.jpg\", \"elephants.jpeg\", \"jetpack.jpg\"]\n",
    "images_bytes = []\n",
    "\n",
    "for img_filename in img_filenames:\n",
    "  with open(img_filename, 'rb') as f:\n",
    "      images_bytes.append(f.read())\n",
    "\n",
    "await describe_local_images(images_bytes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few options for captioning this image, ranging from descriptive to more narrative or humorous:\n",
      "\n",
      "**Descriptive:**\n",
      "1.  A stick figure person, wearing a hat, stands on the ground looking up at a cat perched on a tree branch.\n",
      "2.  A simple drawing depicting a cat in a tree and a person on the ground.\n",
      "3.  A black and white line drawing of a person with hands on hips, gazing up at a cat resting in a tree.\n",
      "\n",
      "**Narrative/Interpretive:**\n",
      "4.  The classic dilemma: a cat up a tree, with a person wondering how to get it down.\n",
      "5.  A stick figure contemplates the challenge of a cat who has climbed too high.\n",
      "6.  \"Now what?\" thinks the person below, as the cat relaxes in the tree.\n",
      "\n",
      "**Humorous:**\n",
      "7.  Cat: \"I'm not coming down.\" Person: \"But... dinner?\"\n",
      "8.  Looks like someone needs a very long stick, or a ladder.\n",
      "9.  Tree-climbing cat asserts dominance over ground-bound human.\n",
      "---\n",
      "Here are a few options for a caption, playing on different aspects of the image:\n",
      "\n",
      "**Option 1 (Descriptive & Serene):**\n",
      "A serene moment with a family of Asian elephants, including a young calf, grazing in tall grass beside a dirt road in a lush green forest.\n",
      "\n",
      "**Option 2 (Focus on the Calf & Heartwarming):**\n",
      "An adorable baby elephant takes curious steps alongside its protective family, exploring the vibrant wilderness of its home.\n",
      "\n",
      "**Option 3 (Concise & Evocative):**\n",
      "Wild elephant family enjoying a peaceful stroll through their verdant jungle home.\n",
      "\n",
      "**Option 4 (Detailed & Natural Habitat):**\n",
      "Four wild elephants, including a small calf, forage amongst the dense foliage and tall grasses of their natural habitat, with a forest track visible in the background.\n",
      "\n",
      "**Option 5 (Short & Sweet for Social Media):**\n",
      "Jungle giants and their little one. ❤️ An elephant family on the move!\n",
      "---\n",
      "A handwritten sketch on ruled paper illustrates a \"Jetpack Backpack\" concept, designed to be lightweight and resemble a normal backpack while fitting an 18-inch laptop. The diagram highlights features such as padded strap support, USB-C charging, and retractable, steam-powered boosters described as \"green/clean,\" offering a 15-minute battery life.\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T23:04:46.127016Z",
     "start_time": "2025-09-02T23:04:43.097562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def brewCoffee(color):\n",
    "    print(f\"Start brewCoffee({color})\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(f\"End brewCoffee({color})\")\n",
    "    return f\"{color} Coffee ready\"\n",
    "\n",
    "async def toastBagel():\n",
    "    print(\"Start toastBagel()\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"End toastBagel()\")\n",
    "    return \"Bagel toasted\"\n",
    "\n",
    "async def main():\n",
    "    start = time.time()\n",
    "    #result_coffee = brewCoffee()\n",
    "    #result_bagel = toastBagel()\n",
    "\n",
    "    #batch = asyncio.gather(brewCoffee(\"black\"), brewCoffee(\"white\"), toastBagel())\n",
    "    #result_coffee_black, result_coffee_white, result_bagel = await batch\n",
    "\n",
    "    results = []\n",
    "    batch = asyncio.gather(brewCoffee(\"black\"), brewCoffee(\"white\"), toastBagel())\n",
    "    results = await batch\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    #print(result_coffee_black)\n",
    "    #print(result_coffee_white)\n",
    "    #print(result_bagel)\n",
    "    print(elapsed_time)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start brewCoffee(black)\n",
      "Start brewCoffee(white)\n",
      "Start toastBagel()\n",
      "End toastBagel()\n",
      "End brewCoffee(white)\n",
      "End brewCoffee(black)\n",
      "black Coffee ready\n",
      "white Coffee ready\n",
      "Bagel toasted\n",
      "3.026031017303467\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "colab": {
   "name": "Asynchronous_requests.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
